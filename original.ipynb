{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Game Popularity Prediction\n",
    "This notebook analyzes video game sales data to predict game popularity using machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report # Make sure classification_report is imported\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: Function Definition\n",
    "def train_and_save_model(data_path='video games sales.csv', model_output_path='game_popularity_model.pkl'):\n",
    "    \"\"\"\n",
    "    Loads data, preprocesses, trains a model, and saves the model,\n",
    "    encoders, feature names, and performance metrics to a .pkl file \n",
    "    with the correct structure for Django.\n",
    "    \"\"\"\n",
    "    print(f\"Starting process...\")\n",
    "    print(f\"Loading dataset from: {data_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The dataset file '{data_path}' was not found. Please ensure it's in the same directory as the notebook.\")\n",
    "        return\n",
    "\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Initial dataset shape: {df.shape}\")\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    print(\"\\n--- Starting Preprocessing ---\")\n",
    "    df.dropna(inplace=True) # Drop rows with any missing values\n",
    "    print(f\"Dataset shape after dropping initial NaNs: {df.shape}\")\n",
    "\n",
    "    if 'Year' in df.columns:\n",
    "        df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "        df.dropna(subset=['Year'], inplace=True)\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "    else:\n",
    "        print(\"Warning: 'Year' column not found.\")\n",
    "\n",
    "    if 'Global_Sales' not in df.columns or not pd.api.types.is_numeric_dtype(df['Global_Sales']):\n",
    "        print(\"Error: 'Global_Sales' column is missing or not numeric. Cannot define 'Popularity'.\")\n",
    "        return\n",
    "        \n",
    "    median_global_sales = df['Global_Sales'].median()\n",
    "    df['Popularity'] = (df['Global_Sales'] >= median_global_sales).astype(int)\n",
    "    print(f\"\\nPopularity threshold (median Global_Sales): {median_global_sales}\")\n",
    "\n",
    "    # --- Feature Engineering & Encoding ---\n",
    "    print(\"\\n--- Starting Feature Encoding ---\")\n",
    "    categorical_features = ['Platform', 'Genre', 'Publisher']\n",
    "    encoders_dict = {} \n",
    "\n",
    "    for col in categorical_features:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' for encoding not found. Skipping.\")\n",
    "            continue\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[f'{col}_Encoded'] = le.fit_transform(df[col])\n",
    "        encoders_dict[col] = le \n",
    "        print(f\"Encoded '{col}'.\")\n",
    "\n",
    "    # --- Define Features (X) and Target (y) ---\n",
    "    print(\"\\n--- Defining Features (X) and Target (y) ---\")\n",
    "    sales_columns = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\n",
    "    for scol in sales_columns:\n",
    "        if scol in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[scol]):\n",
    "                df[scol] = pd.to_numeric(df[scol], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Warning: Sales column '{scol}' not found.\")\n",
    "\n",
    "    feature_names_potential = [\n",
    "        'Platform_Encoded', 'Genre_Encoded', 'Publisher_Encoded',\n",
    "        'Year', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales'\n",
    "    ]\n",
    "    \n",
    "    feature_names = [] \n",
    "    for fname in feature_names_potential:\n",
    "        if fname in df.columns and pd.api.types.is_numeric_dtype(df[fname]):\n",
    "            feature_names.append(fname)\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{fname}' not found or not numeric. Excluded.\")\n",
    "\n",
    "    if not feature_names: \n",
    "        print(\"Error: No valid numeric features found for X. Cannot train model.\")\n",
    "        return\n",
    "        \n",
    "    df.dropna(subset=feature_names + ['Popularity'], inplace=True)\n",
    "    if df.empty or df[feature_names].empty or df['Popularity'].empty:\n",
    "        print(\"Error: DataFrame or necessary columns for X/y are empty. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    X = df[feature_names]\n",
    "    y = df['Popularity']\n",
    "    print(f\"\\nSelected features for training: {feature_names}\")\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    if X.empty or y.empty: \n",
    "        print(\"Error: Features (X) or target (y) is empty before split. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # --- Train-Test Split ---\n",
    "    print(\"\\n--- Splitting Data ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "    # --- Model Training ---\n",
    "    print(\"\\n--- Starting Model Training ---\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Model Evaluation (Define 'accuracy' and 'classification_report_dict' HERE) ---\n",
    "    print(\"\\n--- Starting Model Evaluation ---\") \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred) # 'accuracy' is DEFINED\n",
    "    print(f\"\\nModel Accuracy on Test Set: {accuracy:.4f}\")\n",
    "    print(\"Classification Report on Test Set (for notebook viewing):\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0)) \n",
    "    # Define 'classification_report_dict' for saving in the pickle file\n",
    "    classification_report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0) \n",
    "\n",
    "    # --- Prepare and Save Model Package ---\n",
    "    print(f\"\\n--- Saving model, encoders, feature names, and metrics to {model_output_path} ---\")\n",
    "    \n",
    "    platform_le = encoders_dict.get('Platform')\n",
    "    genre_le = encoders_dict.get('Genre')\n",
    "    publisher_le = encoders_dict.get('Publisher')\n",
    "        \n",
    "    if not all([model, platform_le, genre_le, publisher_le, feature_names, 'accuracy' in locals(), 'classification_report_dict' in locals()]):\n",
    "        print(\"CRITICAL Error: Not all components (model, encoders, features, accuracy, classification_report_dict) are defined. CANNOT SAVE PACKAGE.\")\n",
    "        if not ('model' in locals()): print(\"- 'model' is missing\")\n",
    "        if not ('platform_le' in locals()): print(\"- 'platform_le' is missing\")\n",
    "        if not ('genre_le' in locals()): print(\"- 'genre_le' is missing\")\n",
    "        if not ('publisher_le' in locals()): print(\"- 'publisher_le' is missing\")\n",
    "        if not ('feature_names' in locals()): print(\"- 'feature_names' is missing\")\n",
    "        if not ('accuracy' in locals()): print(\"- 'accuracy' is missing\")\n",
    "        if not ('classification_report_dict' in locals()): print(\"- 'classification_report_dict' is missing\")\n",
    "        return\n",
    "\n",
    "    model_package = {\n",
    "        'model': model,\n",
    "        'encoders': { \n",
    "            'Platform': platform_le,\n",
    "            'Genre': genre_le,\n",
    "            'Publisher': publisher_le\n",
    "        },\n",
    "        'feature_names': feature_names, \n",
    "        'unique_platforms_classes': platform_le.classes_.tolist() if platform_le else [],\n",
    "        'unique_genres_classes': genre_le.classes_.tolist() if genre_le else [],\n",
    "        'unique_publishers_classes': publisher_le.classes_.tolist() if publisher_le else [],\n",
    "        \n",
    "        'accuracy': accuracy,                         \n",
    "        'classification_report_dict': classification_report_dict  \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(model_output_path, 'wb') as f:\n",
    "            pickle.dump(model_package, f)\n",
    "        print(f\"\\nModel, encoders, feature names, and metrics successfully saved to {model_output_path}\")\n",
    "        print(\"Structure of saved package:\")\n",
    "        print(f\"  Top-level keys: {list(model_package.keys())}\")\n",
    "        if 'encoders' in model_package and isinstance(model_package['encoders'], dict):\n",
    "            print(f\"  Keys within 'encoders': {list(model_package['encoders'].keys())}\")\n",
    "        else:\n",
    "             print(f\"  Problem with 'encoders' key: {model_package.get('encoders')}\")\n",
    "        print(f\"  Feature names saved: {model_package.get('feature_names')}\")\n",
    "        print(f\"  Accuracy saved: {model_package.get('accuracy')}\")\n",
    "        print(f\"  Classification report dict saved: {'Yes' if 'classification_report_dict' in model_package else 'No'}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model saving: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to run the full model training and saving process...\n",
      "Starting process...\n",
      "Loading dataset from: video games sales.csv\n",
      "Dataset loaded successfully.\n",
      "Initial dataset shape: (16598, 11)\n",
      "\n",
      "--- Starting Preprocessing ---\n",
      "Dataset shape after dropping initial NaNs: (16291, 11)\n",
      "\n",
      "Popularity threshold (median Global_Sales): 0.17\n",
      "\n",
      "--- Starting Feature Encoding ---\n",
      "Encoded 'Platform'.\n",
      "Encoded 'Genre'.\n",
      "Encoded 'Publisher'.\n",
      "\n",
      "--- Defining Features (X) and Target (y) ---\n",
      "\n",
      "Selected features for training: ['Platform_Encoded', 'Genre_Encoded', 'Publisher_Encoded', 'Year', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\n",
      "X shape: (16291, 8), y shape: (16291,)\n",
      "\n",
      "--- Splitting Data ---\n",
      "X_train shape: (13032, 8), y_train shape: (13032,)\n",
      "\n",
      "--- Starting Model Training ---\n",
      "Model training complete.\n",
      "\n",
      "--- Starting Model Evaluation ---\n",
      "\n",
      "Model Accuracy on Test Set: 0.9871\n",
      "Classification Report on Test Set (for notebook viewing):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1597\n",
      "           1       0.99      0.98      0.99      1662\n",
      "\n",
      "    accuracy                           0.99      3259\n",
      "   macro avg       0.99      0.99      0.99      3259\n",
      "weighted avg       0.99      0.99      0.99      3259\n",
      "\n",
      "\n",
      "--- Saving model, encoders, feature names, and metrics to game_popularity_model.pkl ---\n",
      "\n",
      "Model, encoders, feature names, and metrics successfully saved to game_popularity_model.pkl\n",
      "Structure of saved package:\n",
      "  Top-level keys: ['model', 'encoders', 'feature_names', 'unique_platforms_classes', 'unique_genres_classes', 'unique_publishers_classes', 'accuracy', 'classification_report_dict']\n",
      "  Keys within 'encoders': ['Platform', 'Genre', 'Publisher']\n",
      "  Feature names saved: ['Platform_Encoded', 'Genre_Encoded', 'Publisher_Encoded', 'Year', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\n",
      "  Accuracy saved: 0.9871126112304388\n",
      "  Classification report dict saved: Yes\n",
      "\n",
      "Full process finished.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Function Call\n",
    "# Ensure 'video games sales.csv' is in the same directory as this notebook.\n",
    "print(\"Attempting to run the full model training and saving process...\")\n",
    "train_and_save_model() # This line calls the function defined in Cell 2\n",
    "print(\"\\nFull process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
